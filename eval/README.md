This folder contains the evaluation code used in this paper.

* alpaca_eval_local: A local version of [alpaca_eval](https://github.com/tatsu-lab/alpaca_eval), which contains the AlpacaEval2 benchmark.
* FastChat_local: A local version of [FastChat](https://github.com/lm-sys/FastChat/tree/main), which contains the MT-Bench benchmark.
* [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness): the repo that contains the GSM8K and ARC benchmark
* [evalplus](https://github.com/evalplus/evalplus): the repo that contains the MBPP benchmark
* test_split_eval: the scripts to evaluate the model on the test split of the [UltraFeedback dataset ](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized).
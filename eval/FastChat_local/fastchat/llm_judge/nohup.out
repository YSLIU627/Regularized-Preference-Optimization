Gemma's activation function should be approximate GeLU and not exact GeLU.
Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.
Output to data/mt_bench/model_answer/gemma_dpo.jsonl
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.30it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.36it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.93it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.69it/s]
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:28<37:16, 28.31s/it]  2%|▎         | 2/80 [00:58<38:20, 29.50s/it]/home/zhihanliu/anaconda3/envs/zhihan/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
  4%|▍         | 3/80 [01:16<30:59, 24.15s/it]  5%|▌         | 4/80 [01:48<34:34, 27.30s/it]  6%|▋         | 5/80 [02:53<51:18, 41.05s/it]  8%|▊         | 6/80 [03:05<38:22, 31.11s/it]  9%|▉         | 7/80 [03:29<34:58, 28.74s/it] 10%|█         | 8/80 [04:14<40:43, 33.93s/it] 11%|█▏        | 9/80 [05:07<46:59, 39.72s/it] 12%|█▎        | 10/80 [05:14<34:42, 29.75s/it] 14%|█▍        | 11/80 [05:59<39:25, 34.28s/it] 15%|█▌        | 12/80 [06:48<43:53, 38.73s/it] 16%|█▋        | 13/80 [07:38<47:03, 42.14s/it] 18%|█▊        | 14/80 [08:43<54:03, 49.14s/it] 19%|█▉        | 15/80 [09:12<46:34, 43.00s/it] 20%|██        | 16/80 [10:19<53:41, 50.34s/it] 21%|██▏       | 17/80 [11:25<57:57, 55.20s/it] 22%|██▎       | 18/80 [11:37<43:31, 42.12s/it] 24%|██▍       | 19/80 [12:43<49:57, 49.15s/it] 25%|██▌       | 20/80 [13:23<46:26, 46.45s/it] 26%|██▋       | 21/80 [14:29<51:36, 52.48s/it] 28%|██▊       | 22/80 [15:06<46:03, 47.65s/it] 29%|██▉       | 23/80 [15:56<46:06, 48.54s/it] 30%|███       | 24/80 [16:34<42:15, 45.28s/it] 31%|███▏      | 25/80 [17:06<37:43, 41.15s/it] 32%|███▎      | 26/80 [17:27<31:44, 35.27s/it] 34%|███▍      | 27/80 [18:34<39:24, 44.61s/it] 35%|███▌      | 28/80 [19:20<39:15, 45.29s/it] 36%|███▋      | 29/80 [19:52<35:00, 41.19s/it] 38%|███▊      | 30/80 [20:13<29:12, 35.06s/it] 39%|███▉      | 31/80 [20:42<27:05, 33.17s/it] 40%|████      | 32/80 [20:52<21:11, 26.48s/it] 41%|████▏     | 33/80 [21:21<21:11, 27.05s/it] 42%|████▎     | 34/80 [22:01<23:48, 31.05s/it] 44%|████▍     | 35/80 [22:47<26:32, 35.39s/it] 45%|████▌     | 36/80 [23:03<21:43, 29.63s/it] 46%|████▋     | 37/80 [24:11<29:30, 41.18s/it] 48%|████▊     | 38/80 [24:19<21:53, 31.26s/it] 49%|████▉     | 39/80 [24:55<22:14, 32.56s/it] 50%|█████     | 40/80 [26:00<28:15, 42.38s/it] 51%|█████▏    | 41/80 [26:41<27:11, 41.84s/it] 52%|█████▎    | 42/80 [27:27<27:22, 43.22s/it] 54%|█████▍    | 43/80 [28:15<27:27, 44.53s/it] 55%|█████▌    | 44/80 [29:21<30:44, 51.22s/it] 56%|█████▋    | 45/80 [29:49<25:39, 43.98s/it] 57%|█████▊    | 46/80 [30:28<24:04, 42.48s/it] 59%|█████▉    | 47/80 [31:33<27:10, 49.42s/it] 60%|██████    | 48/80 [31:51<21:21, 40.05s/it] 61%|██████▏   | 49/80 [32:11<17:27, 33.79s/it] 62%|██████▎   | 50/80 [33:16<21:40, 43.34s/it] 64%|██████▍   | 51/80 [34:24<24:30, 50.70s/it] 65%|██████▌   | 52/80 [35:12<23:16, 49.86s/it] 66%|██████▋   | 53/80 [35:48<20:38, 45.87s/it] 68%|██████▊   | 54/80 [36:56<22:41, 52.37s/it] 69%|██████▉   | 55/80 [37:22<18:32, 44.51s/it] 70%|███████   | 56/80 [38:29<20:29, 51.21s/it] 71%|███████▏  | 57/80 [39:08<18:10, 47.40s/it] 72%|███████▎  | 58/80 [39:59<17:50, 48.68s/it] 74%|███████▍  | 59/80 [40:50<17:17, 49.39s/it] 75%|███████▌  | 60/80 [41:14<13:51, 41.58s/it] 76%|███████▋  | 61/80 [41:33<11:05, 35.02s/it] 78%|███████▊  | 62/80 [42:17<11:18, 37.71s/it] 79%|███████▉  | 63/80 [43:02<11:16, 39.79s/it] 80%|████████  | 64/80 [43:40<10:28, 39.31s/it] 81%|████████▏ | 65/80 [44:11<09:13, 36.92s/it] 82%|████████▎ | 66/80 [44:37<07:49, 33.51s/it] 84%|████████▍ | 67/80 [45:43<09:23, 43.33s/it] 85%|████████▌ | 68/80 [46:49<10:00, 50.03s/it] 86%|████████▋ | 69/80 [47:54<10:00, 54.62s/it] 88%|████████▊ | 70/80 [48:13<07:19, 43.98s/it] 89%|████████▉ | 71/80 [48:28<05:16, 35.13s/it] 90%|█████████ | 72/80 [49:34<05:54, 44.32s/it] 91%|█████████▏| 73/80 [49:54<04:20, 37.25s/it] 92%|█████████▎| 74/80 [51:03<04:39, 46.65s/it] 94%|█████████▍| 75/80 [51:40<03:38, 43.76s/it] 95%|█████████▌| 76/80 [52:03<02:30, 37.58s/it] 96%|█████████▋| 77/80 [53:10<02:19, 46.34s/it] 98%|█████████▊| 78/80 [53:40<01:23, 41.51s/it] 99%|█████████▉| 79/80 [53:57<00:34, 34.03s/it]100%|██████████| 80/80 [55:03<00:00, 43.76s/it]100%|██████████| 80/80 [55:03<00:00, 41.30s/it]
Gemma's activation function should be approximate GeLU and not exact GeLU.
Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.
Output to data/mt_bench/model_answer/gemma_rdpo_eta0.005_no_decay.jsonl
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.58it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.83it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.97it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.52it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.21it/s]
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:49<1:04:47, 49.21s/it]/home/zhihanliu/anaconda3/envs/zhihan/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
  2%|▎         | 2/80 [01:26<54:34, 41.99s/it]    4%|▍         | 3/80 [02:32<1:08:26, 53.33s/it]  5%|▌         | 4/80 [03:29<1:08:54, 54.40s/it]  6%|▋         | 5/80 [04:21<1:07:20, 53.87s/it]  8%|▊         | 6/80 [04:56<58:26, 47.38s/it]    9%|▉         | 7/80 [05:08<43:18, 35.60s/it] 10%|█         | 8/80 [06:04<50:30, 42.09s/it] 11%|█▏        | 9/80 [06:25<42:05, 35.56s/it] 12%|█▎        | 10/80 [07:02<42:07, 36.11s/it] 14%|█▍        | 11/80 [07:59<48:56, 42.55s/it] 15%|█▌        | 12/80 [09:05<56:09, 49.54s/it] 16%|█▋        | 13/80 [09:49<53:35, 47.99s/it] 18%|█▊        | 14/80 [10:16<45:42, 41.56s/it] 19%|█▉        | 15/80 [10:48<41:53, 38.67s/it] 20%|██        | 16/80 [11:14<37:12, 34.88s/it] 21%|██▏       | 17/80 [11:21<27:57, 26.63s/it] 22%|██▎       | 18/80 [12:04<32:31, 31.47s/it] 24%|██▍       | 19/80 [12:37<32:33, 32.02s/it] 25%|██▌       | 20/80 [12:46<24:57, 24.95s/it] 26%|██▋       | 21/80 [13:23<28:01, 28.51s/it] 28%|██▊       | 22/80 [13:44<25:22, 26.26s/it] 29%|██▉       | 23/80 [14:07<24:06, 25.38s/it] 30%|███       | 24/80 [14:24<21:21, 22.89s/it] 31%|███▏      | 25/80 [14:55<23:03, 25.15s/it] 32%|███▎      | 26/80 [15:34<26:25, 29.37s/it] 34%|███▍      | 27/80 [16:06<26:48, 30.35s/it] 35%|███▌      | 28/80 [16:43<28:00, 32.31s/it] 36%|███▋      | 29/80 [17:32<31:43, 37.32s/it] 38%|███▊      | 30/80 [18:24<34:39, 41.58s/it] 39%|███▉      | 31/80 [18:35<26:32, 32.50s/it] 40%|████      | 32/80 [18:46<20:46, 25.97s/it] 41%|████▏     | 33/80 [19:24<23:15, 29.70s/it] 42%|████▎     | 34/80 [20:23<29:29, 38.47s/it] 44%|████▍     | 35/80 [20:55<27:20, 36.45s/it] 45%|████▌     | 36/80 [21:15<23:13, 31.67s/it] 46%|████▋     | 37/80 [22:23<30:19, 42.32s/it] 48%|████▊     | 38/80 [23:05<29:35, 42.28s/it] 49%|████▉     | 39/80 [23:50<29:29, 43.15s/it] 50%|█████     | 40/80 [24:21<26:23, 39.59s/it] 51%|█████▏    | 41/80 [25:01<25:51, 39.77s/it] 52%|█████▎    | 42/80 [25:42<25:17, 39.94s/it] 54%|█████▍    | 43/80 [25:54<19:26, 31.53s/it] 55%|█████▌    | 44/80 [26:34<20:30, 34.17s/it] 56%|█████▋    | 45/80 [27:05<19:22, 33.21s/it] 57%|█████▊    | 46/80 [27:29<17:19, 30.58s/it] 59%|█████▉    | 47/80 [27:37<12:56, 23.53s/it] 60%|██████    | 48/80 [28:09<14:00, 26.27s/it] 61%|██████▏   | 49/80 [28:18<10:47, 20.89s/it] 62%|██████▎   | 50/80 [28:36<10:04, 20.15s/it] 64%|██████▍   | 51/80 [29:16<12:33, 25.97s/it] 65%|██████▌   | 52/80 [29:29<10:20, 22.18s/it] 66%|██████▋   | 53/80 [30:12<12:45, 28.34s/it] 68%|██████▊   | 54/80 [30:36<11:45, 27.12s/it] 69%|██████▉   | 55/80 [31:06<11:41, 28.04s/it] 70%|███████   | 56/80 [31:29<10:34, 26.45s/it] 71%|███████▏  | 57/80 [31:54<09:59, 26.06s/it] 72%|███████▎  | 58/80 [32:27<10:19, 28.16s/it] 74%|███████▍  | 59/80 [33:19<12:20, 35.25s/it] 75%|███████▌  | 60/80 [33:47<11:05, 33.26s/it] 76%|███████▋  | 61/80 [33:59<08:28, 26.76s/it] 78%|███████▊  | 62/80 [35:07<11:46, 39.24s/it] 79%|███████▉  | 63/80 [35:53<11:39, 41.15s/it] 80%|████████  | 64/80 [36:05<08:39, 32.50s/it] 81%|████████▏ | 65/80 [36:48<08:52, 35.51s/it] 82%|████████▎ | 66/80 [37:20<08:03, 34.51s/it] 84%|████████▍ | 67/80 [37:57<07:38, 35.24s/it] 85%|████████▌ | 68/80 [38:21<06:23, 31.97s/it] 86%|████████▋ | 69/80 [39:01<06:17, 34.28s/it] 88%|████████▊ | 70/80 [39:49<06:22, 38.30s/it] 89%|████████▉ | 71/80 [40:54<06:56, 46.33s/it] 90%|█████████ | 72/80 [41:42<06:15, 46.94s/it] 91%|█████████▏| 73/80 [42:01<04:29, 38.50s/it] 92%|█████████▎| 74/80 [42:21<03:18, 33.14s/it] 94%|█████████▍| 75/80 [43:27<03:34, 42.83s/it] 95%|█████████▌| 76/80 [43:28<02:01, 30.33s/it] 96%|█████████▋| 77/80 [44:07<01:38, 32.92s/it] 98%|█████████▊| 78/80 [45:09<01:23, 41.54s/it] 99%|█████████▉| 79/80 [45:44<00:39, 39.73s/it]100%|██████████| 80/80 [46:41<00:00, 44.92s/it]100%|██████████| 80/80 [46:41<00:00, 35.02s/it]
Gemma's activation function should be approximate GeLU and not exact GeLU.
Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.
Output to data/mt_bench/model_answer/gemma_rdpo_eta0.1_no_decay.jsonl
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.53it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.56it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.59it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.98it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.80it/s]
  0%|          | 0/80 [00:00<?, ?it/s]/home/zhihanliu/anaconda3/envs/zhihan/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
  1%|▏         | 1/80 [00:05<07:34,  5.75s/it]  2%|▎         | 2/80 [00:13<08:40,  6.67s/it]  4%|▍         | 3/80 [00:39<20:13, 15.76s/it]  5%|▌         | 4/80 [01:22<33:17, 26.28s/it]  6%|▋         | 5/80 [01:27<23:17, 18.63s/it]  8%|▊         | 6/80 [01:49<24:22, 19.77s/it]  9%|▉         | 7/80 [01:59<20:21, 16.73s/it] 10%|█         | 8/80 [02:08<17:14, 14.36s/it] 11%|█▏        | 9/80 [02:15<14:12, 12.01s/it] 12%|█▎        | 10/80 [02:32<15:50, 13.58s/it] 14%|█▍        | 11/80 [02:45<15:21, 13.36s/it] 15%|█▌        | 12/80 [03:13<20:05, 17.73s/it] 16%|█▋        | 13/80 [03:18<15:28, 13.85s/it] 18%|█▊        | 14/80 [03:33<15:45, 14.33s/it] 19%|█▉        | 15/80 [04:02<20:11, 18.65s/it] 20%|██        | 16/80 [04:32<23:35, 22.12s/it] 21%|██▏       | 17/80 [04:50<21:50, 20.80s/it] 22%|██▎       | 18/80 [05:20<24:30, 23.71s/it] 24%|██▍       | 19/80 [05:31<20:02, 19.71s/it] 25%|██▌       | 20/80 [05:59<22:08, 22.15s/it] 26%|██▋       | 21/80 [06:19<21:20, 21.70s/it] 28%|██▊       | 22/80 [06:36<19:29, 20.16s/it] 29%|██▉       | 23/80 [06:38<14:08, 14.89s/it] 30%|███       | 24/80 [06:57<14:56, 16.01s/it] 31%|███▏      | 25/80 [07:05<12:23, 13.52s/it] 32%|███▎      | 26/80 [07:09<09:47, 10.87s/it] 34%|███▍      | 27/80 [07:38<14:13, 16.10s/it] 35%|███▌      | 28/80 [07:47<12:06, 13.97s/it] 36%|███▋      | 29/80 [08:01<12:04, 14.20s/it] 38%|███▊      | 30/80 [08:03<08:34, 10.29s/it] 39%|███▉      | 31/80 [08:29<12:16, 15.02s/it] 40%|████      | 32/80 [08:56<14:52, 18.59s/it] 41%|████▏     | 33/80 [09:02<11:36, 14.82s/it] 42%|████▎     | 34/80 [09:20<12:07, 15.82s/it] 44%|████▍     | 35/80 [09:25<09:30, 12.68s/it] 45%|████▌     | 36/80 [09:50<12:02, 16.42s/it] 46%|████▋     | 37/80 [10:13<13:10, 18.38s/it] 48%|████▊     | 38/80 [10:33<13:10, 18.83s/it] 49%|████▉     | 39/80 [10:48<12:06, 17.72s/it] 50%|█████     | 40/80 [11:11<12:47, 19.19s/it] 51%|█████▏    | 41/80 [11:33<13:00, 20.01s/it] 52%|█████▎    | 42/80 [12:26<19:01, 30.05s/it] 54%|█████▍    | 43/80 [12:47<16:49, 27.27s/it] 55%|█████▌    | 44/80 [12:53<12:29, 20.81s/it] 56%|█████▋    | 45/80 [13:19<13:02, 22.36s/it] 57%|█████▊    | 46/80 [13:51<14:26, 25.47s/it] 59%|█████▉    | 47/80 [14:10<12:50, 23.36s/it] 60%|██████    | 48/80 [14:31<12:02, 22.59s/it] 61%|██████▏   | 49/80 [14:33<08:36, 16.65s/it] 62%|██████▎   | 50/80 [14:42<07:07, 14.24s/it] 64%|██████▍   | 51/80 [15:07<08:24, 17.38s/it] 65%|██████▌   | 52/80 [15:48<11:30, 24.65s/it] 66%|██████▋   | 53/80 [16:08<10:22, 23.06s/it] 68%|██████▊   | 54/80 [16:26<09:23, 21.66s/it] 69%|██████▉   | 55/80 [16:52<09:29, 22.80s/it] 70%|███████   | 56/80 [17:06<08:10, 20.43s/it] 71%|███████▏  | 57/80 [17:16<06:32, 17.06s/it] 72%|███████▎  | 58/80 [17:29<05:48, 15.86s/it] 74%|███████▍  | 59/80 [18:20<09:16, 26.52s/it] 75%|███████▌  | 60/80 [18:51<09:18, 27.90s/it] 76%|███████▋  | 61/80 [19:14<08:21, 26.37s/it] 78%|███████▊  | 62/80 [19:24<06:25, 21.40s/it] 79%|███████▉  | 63/80 [19:44<05:54, 20.88s/it] 80%|████████  | 64/80 [20:12<06:10, 23.18s/it] 81%|████████▏ | 65/80 [20:35<05:44, 22.97s/it] 82%|████████▎ | 66/80 [20:41<04:10, 17.86s/it] 84%|████████▍ | 67/80 [21:21<05:18, 24.51s/it] 85%|████████▌ | 68/80 [21:22<03:32, 17.75s/it] 86%|████████▋ | 69/80 [21:57<04:09, 22.70s/it] 88%|████████▊ | 70/80 [22:37<04:38, 27.89s/it] 89%|████████▉ | 71/80 [23:10<04:24, 29.35s/it] 90%|█████████ | 72/80 [23:36<03:46, 28.36s/it] 91%|█████████▏| 73/80 [23:40<02:29, 21.32s/it] 92%|█████████▎| 74/80 [23:52<01:50, 18.42s/it] 94%|█████████▍| 75/80 [24:11<01:33, 18.68s/it] 95%|█████████▌| 76/80 [24:27<01:10, 17.69s/it] 96%|█████████▋| 77/80 [24:40<00:49, 16.34s/it] 98%|█████████▊| 78/80 [25:42<00:59, 29.99s/it] 99%|█████████▉| 79/80 [26:18<00:31, 31.94s/it]100%|██████████| 80/80 [26:42<00:00, 29.48s/it]100%|██████████| 80/80 [26:42<00:00, 20.03s/it]
Stats:
{
    "bench_name": "mt_bench",
    "mode": "single",
    "judge": "gpt-4",
    "baseline": null,
    "model_list": [
        "gemma_dpo",
        "gemma_rdpo_eta0.005_no_decay",
        "gemma_rdpo_eta0.1_no_decay"
    ],
    "total_num_questions": 80,
    "total_num_matches": 480,
    "output_path": "data/mt_bench/model_judgment/gpt-4_single.jsonl"
}
  0%|          | 0/480 [00:00<?, ?it/s]  0%|          | 0/480 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/zhihanliu/zhihan/RDPO/FastChat_local/fastchat/llm_judge/gen_judgment.py", line 309, in <module>
    play_a_match_func(match, output_file=output_file)
  File "/home/zhihanliu/zhihan/RDPO/FastChat_local/fastchat/llm_judge/common.py", line 203, in play_a_match_single
    score, user_prompt, judgment = run_judge_single(
  File "/home/zhihanliu/zhihan/RDPO/FastChat_local/fastchat/llm_judge/common.py", line 161, in run_judge_single
    conv = get_conversation_template(model)
  File "/home/zhihanliu/zhihan/RDPO/FastChat_local/fastchat/model/model_adapter.py", line 389, in get_conversation_template
    adapter = get_model_adapter(model_path)
  File "/home/zhihanliu/zhihan/RDPO/FastChat_local/fastchat/model/model_adapter.py", line 161, in get_model_adapter
    raise ValueError(f"No valid model adapter for {model_path}")
ValueError: No valid model adapter for gpt-4
